{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Structuring for GPT-3.5: Role-Based Conversation Data</h1>"
      ],
      "metadata": {
        "id": "izxg3n2k8AzD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoF4Ln-u7_KD"
      },
      "outputs": [],
      "source": [
        "conversation = [\n",
        "    {\"role\": \"system\", \"content\": \"You are an investment advice assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Is it a good time to invest in stocks?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"It depends on the market conditions and your personal financial goals. It's often wise to consult with a financial advisor.\"}\n",
        "]\n",
        "\n",
        "# Save to a JSON file with proper formatting\n",
        "with open('formatted_data.json', 'w') as file:\n",
        "    json.dump({\"messages\": conversation}, file, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Splitting Data: Training and Validation Sets</h1>"
      ],
      "metadata": {
        "id": "voJu1Ymh8Jpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    data, labels, test_size=0.2, stratify=labels, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "5z-dAk_G8HWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Serialization to JSONL for Training</h1>"
      ],
      "metadata": {
        "id": "fFvv6Cs98VuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def serialize_to_jsonl(data_entries):\n",
        "    with open('output.jsonl', 'w') as file:\n",
        "        for entry in data_entries:\n",
        "            json_object = json.dumps({\n",
        "                'prompt': entry['question'],\n",
        "                'completion': entry['answer']\n",
        "            })\n",
        "            file.write(json_object + '\\n')\n",
        "\n",
        "# Example entries\n",
        "data_entries = [\n",
        "    {'question': 'What is the capital of France?', 'answer': 'Paris'},\n",
        "    {'question': 'What is the largest planet in our solar system?', 'answer': 'Jupiter'}\n",
        "]\n",
        "serialize_to_jsonl(data_entries)"
      ],
      "metadata": {
        "id": "14N7DFql8cfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Uploading Data for Fine-Tuning with OpenAI</h1>"
      ],
      "metadata": {
        "id": "obX9HPTH8fkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=\"your api key\")\n",
        "\n",
        "# Assuming you've already installed the OpenAI library and set your API key\n",
        "response = client.files.create(\n",
        "    file=open(\"training_data.jsonl\", \"rb\"),\n",
        "    purpose='fine-tune'\n",
        ")\n",
        "\n",
        "print(\"Uploaded file ID:\", response['id'])"
      ],
      "metadata": {
        "id": "4R3LOUJz8mcl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}